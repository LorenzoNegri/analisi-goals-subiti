{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analisi_goals_subiti.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzoNegri/analisi-goals-subiti/blob/master/Analisi_goals_subiti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG5gvYjDDW0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "01cf47d9-a6e7-4011-ce12-e262b616f869"
      },
      "source": [
        "#@title Imports and Global Variables (run this cell first)  { display-mode: \"form\" }\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "!pip3 install -q wget\n",
        "from __future__ import absolute_import, division, print_function\n",
        "#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)\n",
        "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
        "import warnings\n",
        "warnings.filterwarnings(warning_status)\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
        "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/))\n",
        "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
        "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
        "import matplotlib.axes as axes;\n",
        "from matplotlib.patches import Ellipse\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set_context('notebook')\n",
        "from IPython.core.pylabtools import figsize\n",
        "#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
        "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
        "%config InlineBackend.figure_format = notebook_screen_res\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "tfe = tf.contrib.eager\n",
        "\n",
        "# Eager Execution\n",
        "#@markdown Check the box below if you want to use [Eager Execution](https://www.tensorflow.org/guide/eager)\n",
        "#@markdown Eager execution provides An intuitive interface, Easier debugging, and a control flow comparable to Numpy. You can read more about it on the [Google AI Blog](https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html)\n",
        "use_tf_eager = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Use try/except so we can easily re-execute the whole notebook.\n",
        "if use_tf_eager:\n",
        "    try:\n",
        "        tf.enable_eager_execution()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "  \n",
        "def evaluate(tensors):\n",
        "    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
        "    Args:\n",
        "    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
        "        `namedtuple` or combinations thereof.\n",
        "\n",
        "    Returns:\n",
        "        ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
        "          `EagerTensor`s replaced by Numpy `ndarray`s.\n",
        "    \"\"\"\n",
        "    if tf.executing_eagerly():\n",
        "        return tf.contrib.framework.nest.pack_sequence_as(\n",
        "            tensors,\n",
        "            [t.numpy() if tf.contrib.framework.is_tensor(t) else t\n",
        "             for t in tf.contrib.framework.nest.flatten(tensors)])\n",
        "    return sess.run(tensors)\n",
        "\n",
        "class _TFColor(object):\n",
        "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
        "    red = '#F15854'\n",
        "    blue = '#5DA5DA'\n",
        "    orange = '#FAA43A'\n",
        "    green = '#60BD68'\n",
        "    pink = '#F17CB0'\n",
        "    brown = '#B2912F'\n",
        "    purple = '#B276B2'\n",
        "    yellow = '#DECF3F'\n",
        "    gray = '#4D4D4D'\n",
        "    def __getitem__(self, i):\n",
        "        return [\n",
        "            self.red,\n",
        "            self.orange,\n",
        "            self.green,\n",
        "            self.blue,\n",
        "            self.pink,\n",
        "            self.brown,\n",
        "            self.purple,\n",
        "            self.yellow,\n",
        "            self.gray,\n",
        "        ][i % 9]\n",
        "TFColor = _TFColor()\n",
        "\n",
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "reset_sess()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "752Sq8LzFiXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a8e6262-d402-4b32-dcaa-0b8eb1160032"
      },
      "source": [
        "import wget\n",
        "url = 'https://github.com/LorenzoNegri/analisi-goals-subiti/blob/master/data/milan_goals.csv'\n",
        "filename = wget.download(url)\n",
        "filename"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'milan_goals.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dus0YUqZI7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}